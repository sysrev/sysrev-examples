{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene NER using PySysrev and Human Review (Part III)\n",
    "<span style=\"color:gray\">James Borden, Nole Lin</span>\n",
    "\n",
    "In this series on the Sysrev tool, we build a Named Entity Recognition (NER) model for genes.  We use data from 2000 abstracts reviewed in the sysrev [Gene Hunter project](https://sysrev.com/p/3144). This third part of the series details how we can evaluate our model .\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "1. **Evaluate Model** on Gene Hunter text to test performance\n",
    "2. **Demonstrate** our model in action on example sentences\n",
    "\n",
    "We start by training on our processed data and separate 20% of the training set into a test set. We will train for 20 epochs with a dropout rate of 0.2. The sysrev [Gene Hunter project](https://sysrev.com/p/3144) has ~1200 annotated articles, we are careful to split are train and test sets to avoid shared articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984 train instances 246 test instances\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import spacy, sklearn, PySysrev, random, sys\n",
    "\n",
    "GENE_DATA   = PySysrev.processAnnotations(project_id=3144, label='GENE')\n",
    "train, test = GENE_DATA[:int(0.8 * len(GENE_DATA))], GENE_DATA[-int(0.2 * len(GENE_DATA)):]\n",
    "print(\"{} train instances {} test instances\".format(len(train),len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model\n",
    "Now that we have some training/testing data we can create a gene identification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 done!\n"
     ]
    }
   ],
   "source": [
    "# create nlp model\n",
    "nlp = spacy.blank('en')\n",
    "ner = nlp.create_pipe('ner')\n",
    "ner.add_label('GENE')\n",
    "nlp.add_pipe(ner)\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "# train model\n",
    "epochs = 20\n",
    "for itn in range(epochs):\n",
    "    sys.stdout.write(\"{} \".format(itn))\n",
    "    text, annotations = zip(*train) #unzip text/annotations\n",
    "    nlp.update(text, annotations, sgd=optimizer, drop=0.2,losses=losses)\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model\n",
    "Now that we have a model, let's evaluate performance. Spacy.io provides `spacy.scorer.Scorer` which we use to evaluate **true positives** (genes correctly identified as genes), **false negatives** (genes incorrectly identified as non-genes) and **false positives** (non-genes incorrectly classified as genes).  These numbers allow us to calculate **Recall** or the percent of genes that were captured by the model and **Precision** or the proportion of gene identifications that were correct relative to all gene identifications.\n",
    "\n",
    "Recall is important because we don't want to miss any genes.  The gene NER will be used to identify relationships between genes, diseases, chemicals and more.  Randomly missing some genes is ok, but a low recall may indicate that the model misses specific sets of genes in a *biased* manner.  This would make the model much less useful in identifying gene relationships.\n",
    "\n",
    "Precision is a little less important than recall.  Ideally the model doesn't misclassify large numbers of non-genes as genes.  In practice, this might happen when tokens that are used as genes but also have other meanings (like FAT).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='margin: auto;width:50%'><table>\n",
       "<tbody>\n",
       "<tr><td>     </td><td>TP  </td><td>FN </td><td>FP </td><td>Recall        </td><td>Precision     </td></tr>\n",
       "<tr><td>TEST </td><td>203 </td><td>175</td><td>113</td><td>0.537037037037</td><td>0.642405063291</td></tr>\n",
       "<tr><td>TRAIN</td><td>1390</td><td>289</td><td>272</td><td>0.827873734366</td><td>0.836341756919</td></tr>\n",
       "</tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creates a spacy_io 'Scorer' object with accuracy metrics\n",
    "def evaluate(data):\n",
    "    scorer = spacy.scorer.Scorer()\n",
    "    for text,entity_offsets in data: \n",
    "        gold_value    = spacy.gold.GoldParse(nlp.make_doc(text),entities=entity_offsets.get('entities'))\n",
    "        pred_value    = nlp(text)\n",
    "        try: \n",
    "            scorer.score(pred_value,gold_value)\n",
    "        except ValueError:\n",
    "            pass; # spacy has rare error w/ score fn - https://github.com/explosion/spaCy/issues/2661\n",
    "    return scorer\n",
    "\n",
    "# build evaluations\n",
    "tests_eval, train_eval = evaluate(test).ner, evaluate(train).ner\n",
    "mat = [[\"\",\"TP\",\"FN\",\"FP\",\"Recall\",\"Precision\"],\n",
    "       [\"TEST\", tests_eval.tp, tests_eval.fn, tests_eval.fp, tests_eval.recall, tests_eval.precision],\n",
    "       [\"TRAIN\",train_eval.tp, train_eval.fn, train_eval.fp, train_eval.recall, train_eval.precision]]\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "display(HTML(\"<div style='margin: auto;width:50%'>{}</div>\".format(tabulate.tabulate(mat,tablefmt='html'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tomlue/82.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly as py\n",
    "trace1 = py.graph_objs.Bar(x=['gene recall', 'precision'],y=[tests_eval.recall, tests_eval.precision],name='Test')\n",
    "trace2 = py.graph_objs.Bar(x=['gene recall', 'precision'],y=[train_eval.recall, train_eval.precision],name='Train')\n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2], layout=py.graph_objs.Layout(barmode='group'))\n",
    "py.plotly.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that our recall and precision are pretty good! Not perfect, but we only have a few thousand paragraph annotations.  We may be able to do much better with additional model tuning, but we can also improve our models by continuing to run the gene hunter review. The evaluation on the training data is significantly stronger than the test data.  This may indicate overfitting on specific genes, or possibly that distinct gene names occur in the test set without any training examples.\n",
    "\n",
    "Now, we look at specific sentences to see how our model performs in detecting gene terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific examples\n",
    "In the below examples we consider a few basic example sentences.\n",
    "In the first example the model is able to extract \"HMOX\" and \"UGT1A1\" correctly and exclude the rest of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='background-color: lightblue; padding:10px'><div class=\"entities\" style=\"line-height: 2.5\">The aim of our study was to assess the possible relationships among heme oxygenase (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    HMOX\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GENE</span>\n",
       "</mark>\n",
       "), bilirubin UDP-glucuronosyl transferase (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UGT1A1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GENE</span>\n",
       "</mark>\n",
       ") promoter gene variations, serum bilirubin levels, and Fabry disease (FD).</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"The aim of our study was to assess the possible relationships among heme oxygenase (HMOX), bilirubin UDP-glucuronosyl transferase (UGT1A1) promoter gene variations, serum bilirubin levels, and Fabry disease (FD).\")\n",
    "html_ner_prediction = spacy.displacy.render(doc, style='ent')\n",
    "display(HTML(\"<div style='background-color: lightblue; padding:10px'>{}</div>\".format(html_ner_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the model is able to nicely detect an unconventional gene name with a hyphen in the term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='background-color: lightblue; padding:10px'><div class=\"entities\" style=\"line-height: 2.5\">Differential Requirement of Human Cytomegalovirus \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UL112-113\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GENE</span>\n",
       "</mark>\n",
       " Protein Isoforms for Viral Replication.</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Differential Requirement of Human Cytomegalovirus UL112-113 Protein Isoforms for Viral Replication.\")\n",
    "html_ner_prediction = spacy.displacy.render(doc, style='ent')\n",
    "display(HTML(\"<div style='background-color: lightblue; padding:10px'>{}</div>\".format(html_ner_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we now see some flaws in our model. The below sentence contains two gene names \"MDM2\" and \"p53.\" But because they are separated by a slash instead of a space, the model is unable to identify the genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/py27/lib/python2.7/runpy.py:174: UserWarning:\n",
      "\n",
      "[W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='background-color: lightblue; padding:10px'><div class=\"entities\" style=\"line-height: 2.5\">Furthermore, our results demonstrate that miR-365 functions as an upstream regulator of MDM2/p53 expression, cell cycle progression and apoptosis in trophoblasts</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Furthermore, our results demonstrate that miR-365 functions as an upstream regulator of MDM2/p53 expression, cell cycle progression and apoptosis in trophoblasts\")\n",
    "html_ner_prediction = spacy.displacy.render(doc, style='ent')\n",
    "display(HTML(\"<div style='background-color: lightblue; padding:10px'>{}</div>\".format(html_ner_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other times, the model is only able to get one of the genes in the sentence. \"SPI\" is also a gene, but is not highlighted as only \"malat1\" is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='background-color: lightblue; padding:10px'><div class=\"entities\" style=\"line-height: 2.5\">showed that \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    malat1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GENE</span>\n",
       "</mark>\n",
       "Â M5 interacts with the C-terminal domain of SP1 by RNA immunoprecipitation (RIP) assay coupled with UV cross-linking</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"showed that malat1\\xa0M5 interacts with the C-terminal domain of SP1 by RNA immunoprecipitation (RIP) assay coupled with UV cross-linking\")\n",
    "html_ner_prediction = spacy.displacy.render(doc, style='ent')\n",
    "\n",
    "display(HTML(\"<div style='background-color: lightblue; padding:10px'>{}</div>\".format(html_ner_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, our trained model shows promising results in the test and train metrics, as well as specific identification tasks. Some things we could do to improve model performance would be to look into tuning hyperparameters such as the number of epochs and the dropout rate. But with our current working model, we will look into turning it into a web application with an API as our next step, documented in the next post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
